

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>sas2spark.procs &mdash; sas2spark 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            sas2spark
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Documentation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">sas2spark</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">sas2spark.procs</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for sas2spark.procs</h1><div class="highlight"><pre>
<span></span><span class="c1"># --- src/sas2spark/procs.py ---</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pandas.core.series</span><span class="w"> </span><span class="kn">import</span> <span class="n">Series</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pandas.core.frame</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataFrame</span>

<span class="c1"># For PySpark support</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataFrame</span> <span class="k">as</span> <span class="n">SparkDataFrame</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">SparkDataFrame</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># type: ignore</span>
    <span class="n">F</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="proc_freq">
<a class="viewcode-back" href="../../api.html#sas2spark.procs.proc_freq">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">proc_freq</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">DataFrame</span><span class="p">,</span> <span class="s2">&quot;SparkDataFrame&quot;</span><span class="p">],</span>
    <span class="n">tables</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">noprint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
    <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">DataFrame</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Series</span><span class="p">]],</span>
    <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;SparkDataFrame&quot;</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;SparkDataFrame&quot;</span><span class="p">]],</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mimics the functionality of SAS PROC FREQ for Pandas and PySpark DataFrames.</span>

<span class="sd">    Calculates frequency counts and percentages for categorical columns in a DataFrame.</span>
<span class="sd">    Supports optional weighting.</span>

<span class="sd">    Args:</span>
<span class="sd">        data: The input Pandas or PySpark DataFrame.</span>
<span class="sd">        tables: A list of column names to analyze. These columns should be categorical.</span>
<span class="sd">        weights: (Optional) The name of a column containing frequency weights.</span>
<span class="sd">        noprint: (Optional) If True, suppresses printing of the output. The function</span>
<span class="sd">            will still return the results.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tuple containing:</span>
<span class="sd">        - A list of DataFrames (Pandas) or SparkDataFrames, one for each table.</span>
<span class="sd">          Each DataFrame contains the frequency counts and percentages for the</span>
<span class="sd">          specified column. The columns in each output DataFrame are:</span>
<span class="sd">            - `[column_name]` (the analyzed column)</span>
<span class="sd">            - `Frequency` (the count of each unique value)</span>
<span class="sd">            - `Percent` (the percentage of each unique value)</span>
<span class="sd">            - `Weighted Frequency` (if `weights` is provided)</span>
<span class="sd">            - `Weighted Percent` (if `weights` is provided)</span>
<span class="sd">        - (Pandas only) A Pandas Series containing the overall frequency counts</span>
<span class="sd">          if `weights` is not None. For PySpark, this will be None.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError: If the input data is not a Pandas or PySpark DataFrame, or if</span>
<span class="sd">            `tables` is not a list.</span>
<span class="sd">        ValueError: If any of the columns specified in `tables` or `weights`</span>
<span class="sd">            do not exist in the DataFrame.</span>
<span class="sd">        ImportError: If PySpark is used but not installed.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; data_pd = pd.DataFrame({&#39;A&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;a&#39;, &#39;c&#39;, &#39;b&#39;, &#39;a&#39;],</span>
<span class="sd">        ...                         &#39;B&#39;: [&#39;x&#39;, &#39;y&#39;, &#39;x&#39;, &#39;y&#39;, &#39;x&#39;, &#39;y&#39;],</span>
<span class="sd">        ...                         &#39;C&#39;: [1, 2, 1, 2, 1, 2],</span>
<span class="sd">        ...                         &#39;W&#39;: [1, 2, 1, 2, 1, 2]})</span>
<span class="sd">        &gt;&gt;&gt; result_pd, overall_pd = proc_freq(data_pd, tables=[&#39;A&#39;, &#39;B&#39;], weights=&#39;W&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # Example output structure (actual print depends on noprint flag)</span>

<span class="sd">        &gt;&gt;&gt; # Example with PySpark (requires PySpark installation)</span>
<span class="sd">        &gt;&gt;&gt; # from pyspark.sql import SparkSession</span>
<span class="sd">        &gt;&gt;&gt; # spark = SparkSession.builder.appName(&quot;ProcFreqExample&quot;).getOrCreate()</span>
<span class="sd">        &gt;&gt;&gt; # data_spark = spark.createDataFrame(data_pd)</span>
<span class="sd">        &gt;&gt;&gt; # result_spark, overall_spark = proc_freq(data_spark, tables=[&#39;A&#39;, &#39;B&#39;], weights=&#39;W&#39;)</span>
<span class="sd">        &gt;&gt;&gt; # result_spark[0].show() # Example action</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tables</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;The &#39;tables&#39; argument must be a list of column names.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="c1"># Pandas DataFrame processing</span>
        <span class="n">results_pd</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">overall_weights_pd</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Series</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">total_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">total_rows</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
             <span class="k">if</span> <span class="ow">not</span> <span class="n">noprint</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: Input Pandas DataFrame is empty.&quot;</span><span class="p">)</span>
             <span class="k">return</span> <span class="p">[],</span> <span class="kc">None</span> <span class="c1"># Return empty results for empty dataframe</span>


        <span class="k">if</span> <span class="n">weights</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">weights</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weight column &#39;</span><span class="si">{</span><span class="n">weights</span><span class="si">}</span><span class="s2">&#39; not found in DataFrame.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">weights</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                 <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weight column &#39;</span><span class="si">{</span><span class="n">weights</span><span class="si">}</span><span class="s2">&#39; contains null values.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">pd</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_numeric_dtype</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">weights</span><span class="p">]):</span>
                 <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weight column &#39;</span><span class="si">{</span><span class="n">weights</span><span class="si">}</span><span class="s2">&#39; must be numeric.&quot;</span><span class="p">)</span>

            <span class="n">overall_weights_pd</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">weights</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
            <span class="n">total_weight</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">weights</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">total_weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                 <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: Total weight is zero. Weighted percentages will be NaN or Inf.&quot;</span><span class="p">)</span>


        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">tables</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Column &#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&#39; not found in DataFrame.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">weights</span><span class="p">:</span>
                <span class="c1"># Calculate weighted frequencies and percentages</span>
                <span class="c1"># Ensure the column used for grouping doesn&#39;t have NaNs temporarily for agg</span>
                <span class="c1"># Or handle NaNs explicitly if needed</span>
                <span class="n">grouped_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="n">col</span><span class="p">])</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">col</span><span class="p">)[</span><span class="n">weights</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s1">&#39;count&#39;</span><span class="p">,</span> <span class="s1">&#39;sum&#39;</span><span class="p">])</span>
                <span class="n">result_df</span> <span class="o">=</span> <span class="n">grouped_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
                    <span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;count&#39;</span><span class="p">:</span> <span class="s1">&#39;Frequency&#39;</span><span class="p">,</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span> <span class="s1">&#39;Weighted Frequency&#39;</span><span class="p">}</span>
                <span class="p">)</span>
                <span class="c1"># Calculate Percent based on total rows before dropping NaNs for grouping</span>
                <span class="n">result_df</span><span class="p">[</span><span class="s1">&#39;Percent&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">result_df</span><span class="p">[</span><span class="s1">&#39;Frequency&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">total_rows</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
                <span class="c1"># Calculate Weighted Percent</span>
                <span class="k">if</span> <span class="n">total_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                     <span class="n">result_df</span><span class="p">[</span><span class="s1">&#39;Weighted Percent&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                         <span class="n">result_df</span><span class="p">[</span><span class="s1">&#39;Weighted Frequency&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">total_weight</span>
                     <span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
                <span class="k">else</span><span class="p">:</span>
                     <span class="n">result_df</span><span class="p">[</span><span class="s1">&#39;Weighted Percent&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)</span> <span class="c1"># Assign NaN if total weight is zero</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Calculate unweighted frequencies and percentages</span>
                <span class="n">counts</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">dropna</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span> <span class="c1"># Include NaNs if present</span>
                <span class="n">counts</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span><span class="p">,</span> <span class="s1">&#39;Frequency&#39;</span><span class="p">]</span>
                <span class="n">counts</span><span class="p">[</span><span class="s1">&#39;Percent&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">counts</span><span class="p">[</span><span class="s1">&#39;Frequency&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">total_rows</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
                <span class="n">result_df</span> <span class="o">=</span> <span class="n">counts</span>

            <span class="n">results_pd</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> <span class="c1"># Sort results for consistency</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">noprint</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--- Frequency Analysis Results (Pandas) ---&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">results_pd</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Table for column: &#39;</span><span class="si">{</span><span class="n">tables</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="c1"># Use to_string for better console output</span>
            <span class="k">if</span> <span class="n">weights</span> <span class="ow">and</span> <span class="n">overall_weights_pd</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Overall Weights Distribution:&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">overall_weights_pd</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;-------------------------------------------&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_pd</span><span class="p">,</span> <span class="n">overall_weights_pd</span>

    <span class="k">elif</span> <span class="n">SparkDataFrame</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">SparkDataFrame</span><span class="p">):</span>
        <span class="c1"># PySpark DataFrame processing</span>
        <span class="n">results_spark</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">overall_weights_spark</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;SparkDataFrame&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># type: ignore</span>

        <span class="n">total_count</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">total_count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">noprint</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: Input Spark DataFrame is empty.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[],</span> <span class="kc">None</span> <span class="c1"># Return empty results for empty dataframe</span>

        <span class="k">if</span> <span class="n">weights</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">weights</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weight column &#39;</span><span class="si">{</span><span class="n">weights</span><span class="si">}</span><span class="s2">&#39; not found in DataFrame.&quot;</span><span class="p">)</span>
            <span class="c1"># Add checks for nulls and numeric type in Spark</span>
            <span class="n">weight_col_type</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">schema</span><span class="p">[</span><span class="n">weights</span><span class="p">]</span><span class="o">.</span><span class="n">dataType</span>
            <span class="c1"># Simple check for numeric types in Spark (might need refinement for all types)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight_col_type</span><span class="p">,</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">IntegerType</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">LongType</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">FloatType</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">DoubleType</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">DecimalType</span><span class="p">)):</span>
                 <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weight column &#39;</span><span class="si">{</span><span class="n">weights</span><span class="si">}</span><span class="s2">&#39; must be numeric in Spark DataFrame.&quot;</span><span class="p">)</span>
            <span class="c1"># Check for nulls (can be expensive on large data)</span>
            <span class="c1"># null_count = data.where(F.col(weights).isNull()).count()</span>
            <span class="c1"># if null_count &gt; 0:</span>
            <span class="c1">#      raise ValueError(f&quot;Weight column &#39;{weights}&#39; contains null values.&quot;)</span>

            <span class="n">overall_weights_spark</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">data</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">total_weight_result</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;total_w&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
            <span class="n">total_weight</span> <span class="o">=</span> <span class="n">total_weight_result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;total_w&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">total_weight_result</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="n">total_weight</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">total_weight</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                 <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: Total weight is zero or null. Weighted percentages will be NaN or Inf.&quot;</span><span class="p">)</span>
                 <span class="n">total_weight</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># Avoid division by zero later</span>


        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">tables</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Column &#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&#39; not found in DataFrame.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">weights</span><span class="p">:</span>
                <span class="c1"># Calculate weighted frequencies and percentages for Spark</span>
                <span class="c1"># Handle potential nulls in the grouping column if necessary</span>
                <span class="n">weighted_counts</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">data</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="n">col</span><span class="p">])</span> <span class="c1"># Drop rows where the grouping column is null</span>
                    <span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">agg</span><span class="p">(</span>
                        <span class="n">F</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">),</span>
                        <span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;Weighted Frequency&quot;</span><span class="p">)</span>
                      <span class="p">)</span>
                <span class="p">)</span>
                <span class="c1"># Calculate Percent based on total count before dropping NaNs</span>
                <span class="n">result_df</span> <span class="o">=</span> <span class="n">weighted_counts</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
                    <span class="s2">&quot;Percent&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="n">total_count</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
                <span class="p">)</span>
                <span class="c1"># Calculate Weighted Percent</span>
                <span class="k">if</span> <span class="n">total_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                     <span class="n">result_df</span> <span class="o">=</span> <span class="n">result_df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
                         <span class="s2">&quot;Weighted Percent&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;Weighted Frequency&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="n">total_weight</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
                     <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                     <span class="c1"># Add a column with null or NaN if total_weight is zero</span>
                     <span class="n">result_df</span> <span class="o">=</span> <span class="n">result_df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;Weighted Percent&quot;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">lit</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;nan&#39;</span><span class="p">)))</span>

                <span class="n">results_spark</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result_df</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="n">col</span><span class="p">))</span> <span class="c1"># Sort results</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Calculate unweighted frequencies and percentages for Spark</span>
                <span class="c1"># Include nulls in counts using groupBy(F.isnull(col)) or similar if needed</span>
                <span class="c1"># Standard groupBy treats nulls as a separate group</span>
                <span class="n">counts</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="s2">&quot;Frequency&quot;</span><span class="p">)</span>
                <span class="n">result_df</span> <span class="o">=</span> <span class="n">counts</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span>
                    <span class="s2">&quot;Percent&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="n">total_count</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
                <span class="p">)</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="n">col</span><span class="p">)</span> <span class="c1"># Sort results</span>
                <span class="n">results_spark</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result_df</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">noprint</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--- Frequency Analysis Results (PySpark) ---&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">results_spark</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Table for column: &#39;</span><span class="si">{</span><span class="n">tables</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
                <span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">weights</span> <span class="ow">and</span> <span class="n">overall_weights_spark</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Overall Weights Distribution:&quot;</span><span class="p">)</span>
                <span class="n">overall_weights_spark</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;--------------------------------------------&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results_spark</span><span class="p">,</span> <span class="n">overall_weights_spark</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Check if SparkDataFrame is None and raise appropriate error</span>
        <span class="k">if</span> <span class="n">SparkDataFrame</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
             <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                 <span class="s2">&quot;Input data is not a Pandas DataFrame. PySpark is not installed or available.&quot;</span>
             <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
             <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                 <span class="s2">&quot;Input data must be a Pandas DataFrame or a PySpark DataFrame.&quot;</span>
             <span class="p">)</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Tao Xu.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>